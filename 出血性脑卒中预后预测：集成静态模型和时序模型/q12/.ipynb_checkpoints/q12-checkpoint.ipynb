{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe8b90e-850c-4981-b574-0cbca1236a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import warnings\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82d476b-c9fd-42b2-ac59-8f52e9a36d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conda install tqdm numpy pandas scipy matplotlib xgboost \n",
    "# conda install -c conda-forge sklearn-contrib-lightning\n",
    "# conda install -c conda-forge tpot-imblearn\n",
    "# conda install lightgbm\n",
    "# conda install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c72c08-d0f0-4429-b5fb-2d90dd45b1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/2023-NPMCM-main/表1-患者列表及临床信息.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/2023-NPMCM-main/表1-患者列表及临床信息.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m data2\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/2023-NPMCM-main/表2-患者影像信息血肿及水肿的体积及位置.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m data3\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/2023-NPMCM-main/表3-患者影像信息血肿及水肿的形状及灰度分布.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/pandas/io/excel/_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[1;32m    505\u001b[0m         io,\n\u001b[1;32m    506\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    507\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    508\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/pandas/io/excel/_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1564\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1565\u001b[0m     )\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1570\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/pandas/io/excel/_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1420\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/2023-NPMCM-main/表1-患者列表及临床信息.xlsx'"
     ]
    }
   ],
   "source": [
    "data1=pd.read_excel('/root/2023-NPMCM-main/表1-患者列表及临床信息.xlsx')\n",
    "data2=pd.read_excel('/root/2023-NPMCM-main/表2-患者影像信息血肿及水肿的体积及位置.xlsx')\n",
    "data3=pd.read_excel('/root/2023-NPMCM-main/表3-患者影像信息血肿及水肿的形状及灰度分布.xlsx')\n",
    "data4=pd.read_excel('/root/2023-NPMCM-main/表4-答案文件.xlsx')\n",
    "data5=pd.read_excel('1b数据.xlsx') #.drop(['ID'], axis=1)\n",
    "\n",
    "data1.rename(columns={data1.columns[0]: \"ID\"}, inplace=True)\n",
    "data2.rename(columns={data2.columns[0]: \"ID\"}, inplace=True)\n",
    "\n",
    "data_f_1=pd.read_excel('/root/2023-NPMCM-main/附表1-检索表格-流水号vs时间.xlsx')\n",
    "data_kz=pd.read_excel('/root/2023-NPMCM-main/q11/扩张及时间.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd822a05-272a-4fcb-a8b8-29e392533352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 转换独热编码\n",
    "xueya_list = []\n",
    "for i in data5['血压']:\n",
    "    y1 = i.split('/')[0]\n",
    "    y2 = i.split('/')[1]\n",
    "    if int(y1) > 139 or int(y1) < 90:\n",
    "        status_i = 0\n",
    "    elif int(y2) > 89 or int(y2) < 60:\n",
    "        status_i = 0\n",
    "    else:\n",
    "        status_i = 1\n",
    "    xueya_list.append(status_i)\n",
    "data5['血压'] = np.array(xueya_list)\n",
    "data5['性别_男'] = data5['性别'].apply(lambda x: 1 if x == '男' else 0)\n",
    "data5['性别_女'] = data5['性别'].apply(lambda x: 1 if x == '女' else 0)\n",
    "data5 = data5.drop(columns=['性别'])\n",
    "x = data5['年龄'].values\n",
    "scaler = MinMaxScaler()\n",
    "x_normalized = scaler.fit_transform(x.reshape(-1, 1))\n",
    "binarizer = Binarizer(threshold=0.5)\n",
    "x_binarized = binarizer.fit_transform(x_normalized)\n",
    "data5['年龄'] = x_binarized\n",
    "data5 = data5.drop(['流水号'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a1bae5-d60e-4623-838e-5dbce15b76f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(data5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939a91e-fba4-4394-8749-bf5b1d044cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "# 比例变量变数值变量，归一化的是数值变量\n",
    "# 假设data5是你的数据框\n",
    "hm_columns = data5.filter(like='HM_').columns.tolist()\n",
    "ed_columns = data5.filter(like='ED_').columns.tolist()\n",
    "hm_columns.pop(0)\n",
    "ed_columns.pop(0)\n",
    "# print(ed_columns)\n",
    "\n",
    "# 获取'HM_volume'和'ED_volume.0'列的值\n",
    "hm_volume = data5['HM_volume']\n",
    "ed_volume = data5['ED_volume']\n",
    "\n",
    "# 将以'HM_'开头的列与'HM_volume'相乘\n",
    "data5[hm_columns] = data5[hm_columns].mul(hm_volume, axis=0)\n",
    "\n",
    "# 将以'ED_'开头的列与'ED_volume.0'相乘\n",
    "data5[ed_columns] = data5[ed_columns].mul(ed_volume, axis=0)\n",
    "# 创建 MinMaxScaler 对象\n",
    "scaler = MinMaxScaler()\n",
    "# 选择要归一化的列（除了 '年龄' 列之外的所有列）\n",
    "columns_to_normalize = [col for col in data5.columns if col != '性别']\n",
    "# 使用 MinMaxScaler 对所选列进行归一化\n",
    "data5[columns_to_normalize] = scaler.fit_transform(data5[columns_to_normalize])\n",
    "train = data5[:100]\n",
    "label = data_kz['是否扩张'].values[:100]\n",
    "predict = data5[100:]\n",
    "sm = SMOTE(random_state=0)\n",
    "xres, yres = sm.fit_resample(train.values, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495eb26c-7d0e-4f0d-8df5-709edcf412de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data5[:100]\n",
    "label = data_kz['是否扩张'].values[:100]\n",
    "predict = data5[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b6003-b680-44fe-95f5-c7d281337474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义参数网格\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth': [5, 10, 20, 30, 40],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 100), (50, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3430e535-52c1-4ee4-93eb-f62a0e2b90a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m xres, yres \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(train\u001b[38;5;241m.\u001b[39mvalues, label)\n\u001b[1;32m      3\u001b[0m xtrain, xvalid, ytrain, yvalid \u001b[38;5;241m=\u001b[39m train_test_split(train\u001b[38;5;241m.\u001b[39mvalues,label,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m xtrain_res, xvalid_res, ytrain_res, yvalid_res \u001b[38;5;241m=\u001b[39m train_test_split(xres,yres,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "xres, yres = sm.fit_resample(train.values, label)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.values,label,random_state=50,test_size=0.2)\n",
    "xtrain_res, xvalid_res, ytrain_res, yvalid_res = train_test_split(xres,yres,random_state=50,test_size=0.2)\n",
    "\n",
    "# 采样前\n",
    "def function_before(model, param_grid, cv_values=[5], n_jobs=16):\n",
    "    best_auc = 0\n",
    "    best_cv = None\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    for cv in cv_values:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=n_jobs)\n",
    "        grid_search.fit(train.values, label)\n",
    "\n",
    "        if grid_search.best_score_ > best_auc:\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_auc = grid_search.best_score_\n",
    "            best_params = grid_search.best_params_\n",
    "            best_cv = cv\n",
    "\n",
    "    if best_model is None:\n",
    "        raise ValueError(\"No model was trained successfully.\")\n",
    "\n",
    "    acc = round(cross_val_score(best_model, train.values, label, cv=best_cv, scoring='accuracy').mean(), 2)\n",
    "    recall = round(cross_val_score(best_model, train.values, label, cv=best_cv, scoring='recall').mean(), 2)\n",
    "    precision = round(cross_val_score(best_model, train.values, label, cv=best_cv, scoring='precision').mean(), 2)\n",
    "    f1 = round(cross_val_score(best_model, train.values, label, cv=best_cv, scoring='f1').mean(), 2)\n",
    "\n",
    "    result_dict = {\n",
    "        'best_model': best_model,\n",
    "        'best_auc': round(best_auc, 4),\n",
    "        'best_params': best_params,\n",
    "        'acc': acc,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'best_cv': best_cv\n",
    "    }\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "cv_values = [5, 10]\n",
    "best_results_rf = function_before(RandomForestClassifier(random_state=100), param_grid_rf, cv_values)\n",
    "best_results_lgbm = function_before(LGBMClassifier(random_state=100), param_grid_lgbm, cv_values)\n",
    "best_results_xgb = function_before(XGBClassifier(random_state=100), param_grid_xgb, cv_values)\n",
    "best_results_svc = function_before(SVC(probability=True, random_state=100), param_grid_svc, cv_values)\n",
    "best_results_mlp = function_before(MLPClassifier(random_state=100), param_grid_mlp, cv_values)\n",
    "best_results_lr = function_before(LogisticRegression(random_state=100), param_grid_lr, cv_values)\n",
    "\n",
    "model0 = best_results_rf['best_model']\n",
    "model1 = best_results_lgbm['best_model']\n",
    "model2 = best_results_xgb['best_model']\n",
    "model3 = best_results_svc['best_model']\n",
    "model4 = best_results_mlp['best_model']\n",
    "model5 = best_results_lr['best_model']\n",
    "\n",
    "model0.fit(xtrain,ytrain)\n",
    "model1.fit(xtrain,ytrain)\n",
    "model2.fit(xtrain,ytrain)\n",
    "model3.fit(xtrain,ytrain)\n",
    "model4.fit(xtrain,ytrain)\n",
    "model5.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb81ec9-f17b-4a5f-934d-79c1a2d3e5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq1_roc_auc(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(采样前)).eps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 30\u001b[0m f([model0, model1, model2, model3, model4, model5], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m f([model0, model1, model2, model3, model4, model5], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model0' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(model_list,name_list,types='train'):\n",
    "    plt.figure(figsize=(8, 7), dpi=100, facecolor='w')    # dpi:每英寸长度的像素点数；facecolor 背景颜色\n",
    "    plt.xlim((-0.01, 1.02))  # x,y 轴刻度的范围\n",
    "    plt.ylim((-0.01, 1.02))\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))  #绘制刻度\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    \n",
    "    if types == 'test':\n",
    "        for model,name in zip(model_list,name_list):\n",
    "            ytest_prob = model.predict_proba(xvalid)[:,1]\n",
    "            fpr, tpr, _ = metrics.roc_curve(yvalid, ytest_prob)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, '-', lw=2.5, label=f'{name} AUC:%.5f' % auc)  # 绘制AUC 曲线\n",
    "    else:\n",
    "        for model,name in zip(model_list,name_list):\n",
    "            ytest_prob = model.predict_proba(xtrain)[:,1]\n",
    "            fpr, tpr, _ = metrics.roc_curve(ytrain, ytest_prob)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, '-', lw=2.5, label=f'{name} AUC:%.5f' % auc)  # 绘制AUC 曲线\n",
    "    plt.legend(loc='best',fontsize=15)    # 设置显示标签的位置\n",
    "    plt.xlabel('假阳率', fontsize=14)   #绘制x,y 坐标轴对应的标签\n",
    "    plt.ylabel('真阳率', fontsize=14)\n",
    "    plt.tick_params(labelsize=23)\n",
    "\n",
    "    plt.grid(b=True, ls=':')  # 绘制网格作为底板;b是否显示网格线；ls表示line style\n",
    "    # plt.savefig(f'q1_roc_auc({types}(采样前)).png',dpi=1000)\n",
    "    plt.savefig(f'q1_roc_auc({types}(采样前)).eps')\n",
    "    plt.show()\n",
    "\n",
    "f([model0, model1, model2, model3, model4, model5], ['RF', 'LGBM', 'XGB', 'SVC', 'MLP', 'LR'], 'test')\n",
    "f([model0, model1, model2, model3, model4, model5], ['RF', 'LGBM', 'XGB', 'SVC', 'MLP', 'LR'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821685d9-a739-48db-a182-9792c1933823",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_grid_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_dict\n\u001b[1;32m     39\u001b[0m cv_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m best_results_rf \u001b[38;5;241m=\u001b[39m function_after(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m), param_grid_rf, cv_values)\n\u001b[1;32m     41\u001b[0m best_results_lgbm \u001b[38;5;241m=\u001b[39m function_after(LGBMClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m), param_grid_lgbm, cv_values)\n\u001b[1;32m     42\u001b[0m best_results_xgb \u001b[38;5;241m=\u001b[39m function_after(XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m), param_grid_xgb, cv_values)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_grid_rf' is not defined"
     ]
    }
   ],
   "source": [
    "# 采样后\n",
    "def function_after(model, param_grid, cv_values=[5], n_jobs=16):\n",
    "    best_auc = 0\n",
    "    best_cv = None\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    for cv in cv_values:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=n_jobs)\n",
    "        grid_search.fit(xres, yres)\n",
    "        \n",
    "        if grid_search.best_score_ > best_auc:\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_auc = grid_search.best_score_\n",
    "            best_params = grid_search.best_params_\n",
    "            best_cv = cv\n",
    "\n",
    "    if best_model is None:\n",
    "        raise ValueError(\"No model was trained successfully.\")\n",
    "\n",
    "    acc = round(cross_val_score(best_model, xres, yres, cv=best_cv, scoring='accuracy').mean(), 2)\n",
    "    recall = round(cross_val_score(best_model, xres, yres, cv=best_cv, scoring='recall').mean(), 2)\n",
    "    precision = round(cross_val_score(best_model, xres, yres, cv=best_cv, scoring='precision').mean(), 2)\n",
    "    f1 = round(cross_val_score(best_model, xres, yres, cv=best_cv, scoring='f1').mean(), 2)\n",
    "    \n",
    "    result_dict = {\n",
    "        'best_model': best_model,\n",
    "        'best_auc': round(best_auc, 4),\n",
    "        'best_params': best_params,\n",
    "        'acc': acc,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1,\n",
    "        'best_cv': best_cv\n",
    "    }\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "cv_values = [5, 10]\n",
    "best_results_rf = function_after(RandomForestClassifier(random_state=100), param_grid_rf, cv_values)\n",
    "best_results_lgbm = function_after(LGBMClassifier(random_state=100), param_grid_lgbm, cv_values)\n",
    "best_results_xgb = function_after(XGBClassifier(random_state=100), param_grid_xgb, cv_values)\n",
    "best_results_svc = function_after(SVC(probability=True, random_state=100), param_grid_svc, cv_values)\n",
    "best_results_mlp = function_after(MLPClassifier(random_state=100), param_grid_mlp, cv_values)\n",
    "best_results_lr = function_after(LogisticRegression(random_state=100), param_grid_lr, cv_values)\n",
    "\n",
    "model0 = best_results_rf['best_model']\n",
    "model1 = best_results_lgbm['best_model']\n",
    "model2 = best_results_xgb['best_model']\n",
    "model3 = best_results_svc['best_model']\n",
    "model4 = best_results_mlp['best_model']\n",
    "model5 = best_results_lr['best_model']\n",
    "\n",
    "model0.fit(xtrain_res,ytrain_res)\n",
    "model1.fit(xtrain_res,ytrain_res)\n",
    "model2.fit(xtrain_res,ytrain_res)\n",
    "model3.fit(xtrain_res,ytrain_res)\n",
    "model4.fit(xtrain_res,ytrain_res)\n",
    "model5.fit(xtrain_res,ytrain_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0f563b-8938-4a0c-acd2-8e7104a8bfaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq1_roc_roc_auc(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m（采样后）).eps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 30\u001b[0m f([model0, model1, model2, model3, model4, model5], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m f([model0, model1, model2, model3, model4, model5], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model0' is not defined"
     ]
    }
   ],
   "source": [
    "def f(model_list,name_list,types='train'):\n",
    "    plt.figure(figsize=(8, 7), dpi=100, facecolor='w')    # dpi:每英寸长度的像素点数；facecolor 背景颜色\n",
    "    plt.xlim((-0.01, 1.02))  # x,y 轴刻度的范围\n",
    "    plt.ylim((-0.01, 1.02))\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))  #绘制刻度\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    \n",
    "    if types == 'test':\n",
    "        for model,name in zip(model_list,name_list):\n",
    "            ytest_prob = model.predict_proba(xvalid_res)[:,1]\n",
    "            fpr, tpr, _ = metrics.roc_curve(yvalid_res, ytest_prob)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, '-', lw=2.5, label=f'{name} AUC:%.5f' % auc)  # 绘制AUC 曲线\n",
    "    else:\n",
    "        for model,name in zip(model_list,name_list):\n",
    "            ytest_prob = model.predict_proba(xtrain_res)[:,1]\n",
    "            fpr, tpr, _ = metrics.roc_curve(ytrain_res, ytest_prob)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, '-', lw=2.5, label=f'{name} AUC:%.5f' % auc)  # 绘制AUC 曲线\n",
    "    plt.legend(loc='best',fontsize=15)    # 设置显示标签的位置\n",
    "    plt.xlabel('假阳率', fontsize=14)   #绘制x,y 坐标轴对应的标签\n",
    "    plt.ylabel('真阳率', fontsize=14)\n",
    "    plt.tick_params(labelsize=23)\n",
    "\n",
    "    plt.grid(b=True, ls=':')  # 绘制网格作为底板;b是否显示网格线；ls表示line style\n",
    "    # plt.savefig(f'q1_roc_roc_auc({types}（采样后）).png',dpi=1000)\n",
    "    plt.savefig(f'q1_roc_roc_auc({types}（采样后）).eps')\n",
    "    plt.show()\n",
    "\n",
    "f([model0, model1, model2, model3, model4, model5], ['RF', 'LGBM', 'XGB', 'SVC', 'MLP', 'LR'], 'test')\n",
    "f([model0, model1, model2, model3, model4, model5], ['RF', 'LGBM', 'XGB', 'SVC', 'MLP', 'LR'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9946d7b1-ee56-456e-b5cc-002d7535e1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_results_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建mlp和svc的DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([best_results_mlp])\n\u001b[1;32m      3\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m      4\u001b[0m df1\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_results_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建mlp和svc的DataFrame\n",
    "df1 = pd.DataFrame([best_results_mlp])\n",
    "df1 = df1.transpose()\n",
    "df1.columns = ['mlp']\n",
    "\n",
    "df2 = pd.DataFrame([best_results_svc])\n",
    "df2 = df2.transpose()\n",
    "df2.columns = ['svc']\n",
    "\n",
    "# 创建RF的DataFrame\n",
    "df_rf = pd.DataFrame([best_results_rf])\n",
    "df_rf = df_rf.transpose()\n",
    "df_rf.columns = ['rf']\n",
    "\n",
    "# 创建LGBM的DataFrame\n",
    "df_lgbm = pd.DataFrame([best_results_lgbm])\n",
    "df_lgbm = df_lgbm.transpose()\n",
    "df_lgbm.columns = ['lgbm']\n",
    "\n",
    "# 创建XGB的DataFrame\n",
    "df_xgb = pd.DataFrame([best_results_xgb])\n",
    "df_xgb = df_xgb.transpose()\n",
    "df_xgb.columns = ['xgb']\n",
    "\n",
    "# 创建LR的DataFrame\n",
    "df_lr = pd.DataFrame([best_results_lr])\n",
    "df_lr = df_lr.transpose()\n",
    "df_lr.columns = ['lr']\n",
    "\n",
    "# 合并所有的DataFrame\n",
    "result_df = pd.concat([df1, df2, df_rf, df_lgbm, df_xgb, df_lr], axis=1)\n",
    "result_df = result_df.T.drop(['best_model', 'best_params'], axis = 1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29107d2-d006-4642-b2d4-78e08ec1e154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_results_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb746a0-c49d-4f98-b9e5-8cf65f0fe457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlp_model = best_results_mlp['best_model']\n",
    "# mlp_model.fit(xres,yres)\n",
    "# mlp_model_result = [round(i,4) for i in mlp_model.predict_proba(data5.values)[:,1]]\n",
    "# mlp_model_result = pd.DataFrame({'扩张概率':mlp_model_result})\n",
    "# mlp_model_result.to_excel('q12扩张概率.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "228f39ae-3777-4a33-970b-661fe24d27ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # 保存最优的参数\n",
    "# mlp_model = best_results_mlp['best_model']\n",
    "# with open('mlp_default_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(mlp_model.get_params(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ea9a3a5-b557-4084-9781-12efdc55b54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # 保存最优的参数\n",
    "# xgb_model = best_results_xgb['best_model']\n",
    "# with open('xgboost_default_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(xgb_model.get_params(), f)\n",
    "\n",
    "# # # # 调用已保存的函数参数\n",
    "# # # with open('xgboost_default_params.pkl', 'rb') as f:\n",
    "# # #     default_params = pickle.load(f)\n",
    "# # # xgb_model = xgb.XGBClassifier(**default_params)\n",
    "# # xgb_model.fit(xres,yres)\n",
    "# # xgb_model_result = [round(i,4) for i in xgb_model.predict_proba(data5.values)[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1d88d0d-185b-4fea-b186-ae08aa404641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xgb_model_result = pd.DataFrame({'扩张概率':xgb_model_result})\n",
    "# xgb_model_result.to_excel('q12扩张概率.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ce093-8ae2-4b25-9aae-3233d2af0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.fit(xres,yres)\n",
    "mlp_model_result = [round(i,4) for i in mlp_model.predict_proba(data5.values)[:,1]]\n",
    "mlp_model_result = pd.DataFrame({'扩张概率':mlp_model_result})\n",
    "mlp_model_result.to_excel('q12扩张概率.xlsx',index=False)\n",
    "# 'name':data1['ID'].values,\n",
    "mlp_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb198af-3a15-4b6a-a86d-ac03c37bd663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaafc2fe-322a-49e1-b29a-f5417da8e214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
