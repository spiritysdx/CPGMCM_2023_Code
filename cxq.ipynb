{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e1ff4ddd-2393-462b-a757-304261587b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib,re,math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f81ec44b-3924-4634-b6ab-ee5361a519d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1=pd.read_excel('表1-患者列表及临床信息.xlsx')\n",
    "data2=pd.read_excel('表2-患者影像信息血肿及水肿的体积及位置.xlsx')\n",
    "data3=pd.read_excel('表3-患者影像信息血肿及水肿的形状及灰度分布.xlsx')\n",
    "data4=pd.read_excel('表4-答案文件.xlsx')\n",
    "\n",
    "data1.rename(columns={data1.columns[0]: \"ID\"}, inplace=True)\n",
    "data2.rename(columns={data2.columns[0]: \"ID\"}, inplace=True)\n",
    "\n",
    "data_f_1=pd.read_excel('附表1-检索表格-流水号vs时间.xlsx')\n",
    "data_f_time=pd.read_excel('时间点.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b0c783c-ae57-4c76-bca7-8578514f5f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 取1a问题对应需要用的数据\n",
    "data1_columns = ['ID','数据集划分', '入院首次影像检查流水号', '发病到首次影像检查时间间隔']\n",
    "data1_1a = data1[data1_columns]\n",
    "\n",
    "data2.rename(columns={data2.columns[0]: \"ID\"}, inplace=True)\n",
    "data2_columns = ['ID'] + [col for col in data2.columns if col.startswith('HM_volume') or col.startswith('随访')] # '首次检查流水号'\n",
    "data2_1a = data2[data2_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3139db4d-23c3-447c-aacf-fffb0e30e765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 合并和保存数据\n",
    "_1a=pd.merge(data1_1a,data2_1a,how='outer',on='ID')\n",
    "# _1a.to_csv('1a数据.csv', index=False, encoding='utf-8')\n",
    "_1a.to_excel('1a数据.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "613ec4f0-1f9a-4d15-b546-c796bd5a8c23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 转换为时间戳格式\n",
    "columns_to_convert = data_f_time.columns[1:]\n",
    "data_f_time[columns_to_convert] = data_f_time[columns_to_convert].apply(pd.to_datetime)\n",
    "# Datetime对象转换为秒级的时间戳形式\n",
    "data_f_time[columns_to_convert] = data_f_time[columns_to_convert].apply(lambda x: x.astype(int) // 10**9)\n",
    "# 将负数的时间戳转变为空值\n",
    "data_f_time[data_f_time.columns[1:]] = data_f_time[data_f_time.columns[1:]].apply(lambda x: x.mask(x < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6a315785-20c3-4523-aa95-3686de65fe73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 找到两个 DataFrame 共有的列名\n",
    "common_columns = data_f_time.columns.intersection(_1a.columns)\n",
    "# 使用 data_f_time 中的列替换 _1a 中的相同列名的列\n",
    "_1a[common_columns] = data_f_time[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d8e854bf-179a-4b20-8c43-9f15fe0cf202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', '入院首次影像检查流水号', '随访1流水号', '随访2流水号', '随访3流水号', '随访4流水号', '随访5流水号',\n",
       "       '随访6流水号', '随访7流水号', '随访8流水号'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81db4167-07df-4722-8cd0-4fbc0c5fe983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', '数据集划分', '入院首次影像检查流水号', '发病到首次影像检查时间间隔', 'HM_volume', '随访1流水号',\n",
       "       'HM_volume.1', '随访2流水号', 'HM_volume.2', '随访3流水号', 'HM_volume.3',\n",
       "       '随访4流水号', 'HM_volume.4', '随访5流水号', 'HM_volume.5', '随访6流水号',\n",
       "       'HM_volume.6', '随访7流水号', 'HM_volume.7', '随访8流水号', 'HM_volume.8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fb478520-4017-47c5-b211-cf2ed3bfc867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['入院首次影像检查流水号', '随访1流水号', '随访2流水号', '随访3流水号', '随访4流水号', '随访5流水号', '随访6流水号', '随访7流水号', '随访8流水号'] ['HM_volume', 'HM_volume.1', 'HM_volume.2', 'HM_volume.3', 'HM_volume.4', 'HM_volume.5', 'HM_volume.6', 'HM_volume.7', 'HM_volume.8']\n"
     ]
    }
   ],
   "source": [
    "# 取时间做散点图\n",
    "result_list = []\n",
    "flow_cols = [col for col in _1a.columns if col.endswith('流水号')]\n",
    "hm_cols = [col for col in _1a.columns if col.startswith('HM_')]\n",
    "print(flow_cols, hm_cols)\n",
    "\n",
    "# 修改寻访的变为以0开始的时间戳\n",
    "cumulative_value_lists = []\n",
    "p = 0 # 更新第几列\n",
    "for i in range(8):\n",
    "    cumulative_value_list = []\n",
    "    q = 0\n",
    "    for j,k,m in zip(_1a[flow_cols[i]], _1a[flow_cols[i+1]], _1a['发病到首次影像检查时间间隔']):\n",
    "        if j == float(np.nan) or k == float(np.nan): # 无记录继承前面的记录\n",
    "            cumulative_value = cumulative_value_lists[p-1][q]\n",
    "        else:\n",
    "            if i == 0:\n",
    "                cumulative_value = 0\n",
    "                cumulative_value += (m * 3600 + (k - j))\n",
    "                cumulative_value_list.append(cumulative_value)\n",
    "            else:\n",
    "                cumulative_value = cumulative_value_lists[p-1][q] # 继承上一次检测的时间戳\n",
    "                cumulative_value += (k - j)\n",
    "                cumulative_value_list.append(cumulative_value)\n",
    "        q += 1 # 更新第几行\n",
    "    cumulative_value_lists.append(cumulative_value_list)\n",
    "    p += 1\n",
    "\n",
    "# 最后才更新数据，前面只存储了每个时间戳以0开始的值\n",
    "for i in range(8):\n",
    "    for j,k,m in zip(_1a[flow_cols[i]], _1a[flow_cols[i+1]], _1a['发病到首次影像检查时间间隔']):\n",
    "        _1a[flow_cols[i+1]] = np.array(cumulative_value_lists[i])\n",
    "\n",
    "# 修改首次入院检查时的时间戳\n",
    "_1a['入院首次影像检查流水号'] = _1a['发病到首次影像检查时间间隔'] * 3600\n",
    "# 此时_1a内流水号全为时间戳形式了\n",
    "\n",
    "# 画总体的散点图\n",
    "'''\n",
    "# [(时间戳，体积大小)]\n",
    "for i,j in zip(flow_cols, hm_cols):\n",
    "    for l,m in zip(_1a[i],_1a[j]):\n",
    "        if l <= 48 * 3600: # 只取48小时内的数据\n",
    "            result_list.append((l,m))\n",
    "\n",
    "# 去除空值再画图\n",
    "result_list = [item for item in result_list if not any(math.isnan(value) for value in item)]\n",
    "\n",
    "x_values = [item[0] for item in result_list]\n",
    "y_values = [item[1] for item in result_list]\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(x_values, y_values)\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('1a')\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('HM_volume')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "selected_cols = []\n",
    "for i,j in zip(flow_cols, hm_cols):\n",
    "    selected_cols.append(i)\n",
    "    selected_cols.append(j)\n",
    "selected_df = _1a[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e681ea5-e158-4a6f-b546-ae2b2aeb8c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>入院首次影像检查流水号</th>\n",
       "      <th>HM_volume</th>\n",
       "      <th>随访1流水号</th>\n",
       "      <th>HM_volume.1</th>\n",
       "      <th>随访2流水号</th>\n",
       "      <th>HM_volume.2</th>\n",
       "      <th>随访3流水号</th>\n",
       "      <th>HM_volume.3</th>\n",
       "      <th>随访4流水号</th>\n",
       "      <th>HM_volume.4</th>\n",
       "      <th>随访5流水号</th>\n",
       "      <th>HM_volume.5</th>\n",
       "      <th>随访6流水号</th>\n",
       "      <th>HM_volume.6</th>\n",
       "      <th>随访7流水号</th>\n",
       "      <th>HM_volume.7</th>\n",
       "      <th>随访8流水号</th>\n",
       "      <th>HM_volume.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>69714</td>\n",
       "      <td>29766.0</td>\n",
       "      <td>74902.0</td>\n",
       "      <td>475590.0</td>\n",
       "      <td>70952.0</td>\n",
       "      <td>935055.0</td>\n",
       "      <td>62831.0</td>\n",
       "      <td>1531938.0</td>\n",
       "      <td>44029.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>47500</td>\n",
       "      <td>53724.0</td>\n",
       "      <td>52271.0</td>\n",
       "      <td>249199.0</td>\n",
       "      <td>47748.0</td>\n",
       "      <td>1612859.0</td>\n",
       "      <td>13055.0</td>\n",
       "      <td>4029091.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>86396</td>\n",
       "      <td>34281.0</td>\n",
       "      <td>106042.0</td>\n",
       "      <td>142545.0</td>\n",
       "      <td>103263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>45498</td>\n",
       "      <td>61107.0</td>\n",
       "      <td>39877.0</td>\n",
       "      <td>301843.0</td>\n",
       "      <td>16622.0</td>\n",
       "      <td>819004.0</td>\n",
       "      <td>8441.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>14832</td>\n",
       "      <td>95283.0</td>\n",
       "      <td>24472.0</td>\n",
       "      <td>352595.0</td>\n",
       "      <td>25477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>19800.0</td>\n",
       "      <td>32559</td>\n",
       "      <td>89575.0</td>\n",
       "      <td>35138.0</td>\n",
       "      <td>452217.0</td>\n",
       "      <td>34241.0</td>\n",
       "      <td>1055942.0</td>\n",
       "      <td>14377.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>18150</td>\n",
       "      <td>4920.0</td>\n",
       "      <td>37650.0</td>\n",
       "      <td>25620.0</td>\n",
       "      <td>140688.0</td>\n",
       "      <td>72240.0</td>\n",
       "      <td>123926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>10080.0</td>\n",
       "      <td>27969</td>\n",
       "      <td>66180.0</td>\n",
       "      <td>27071.0</td>\n",
       "      <td>256680.0</td>\n",
       "      <td>24119.0</td>\n",
       "      <td>1111140.0</td>\n",
       "      <td>3647.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>53154</td>\n",
       "      <td>95520.0</td>\n",
       "      <td>126642.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>14400.0</td>\n",
       "      <td>49019</td>\n",
       "      <td>62940.0</td>\n",
       "      <td>100470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     入院首次影像检查流水号  HM_volume   随访1流水号  HM_volume.1    随访2流水号  HM_volume.2  \\\n",
       "0         9000.0      69714  29766.0      74902.0  475590.0      70952.0   \n",
       "1        10800.0      47500  53724.0      52271.0  249199.0      47748.0   \n",
       "2         7200.0      86396  34281.0     106042.0  142545.0     103263.0   \n",
       "3         3600.0      45498  61107.0      39877.0  301843.0      16622.0   \n",
       "4        18000.0      14832  95283.0      24472.0  352595.0      25477.0   \n",
       "..           ...        ...      ...          ...       ...          ...   \n",
       "155      19800.0      32559  89575.0      35138.0  452217.0      34241.0   \n",
       "156       1800.0      18150   4920.0      37650.0   25620.0     140688.0   \n",
       "157      10080.0      27969  66180.0      27071.0  256680.0      24119.0   \n",
       "158      10800.0      53154  95520.0     126642.0       NaN          NaN   \n",
       "159      14400.0      49019  62940.0     100470.0       NaN          NaN   \n",
       "\n",
       "        随访3流水号  HM_volume.3     随访4流水号  HM_volume.4  随访5流水号  HM_volume.5  \\\n",
       "0     935055.0      62831.0  1531938.0      44029.0     NaN          NaN   \n",
       "1    1612859.0      13055.0  4029091.0         20.0     NaN          NaN   \n",
       "2          NaN          NaN        NaN          NaN     NaN          NaN   \n",
       "3     819004.0       8441.0        NaN          NaN     NaN          NaN   \n",
       "4          NaN          NaN        NaN          NaN     NaN          NaN   \n",
       "..         ...          ...        ...          ...     ...          ...   \n",
       "155  1055942.0      14377.0        NaN          NaN     NaN          NaN   \n",
       "156    72240.0     123926.0        NaN          NaN     NaN          NaN   \n",
       "157  1111140.0       3647.0        NaN          NaN     NaN          NaN   \n",
       "158        NaN          NaN        NaN          NaN     NaN          NaN   \n",
       "159        NaN          NaN        NaN          NaN     NaN          NaN   \n",
       "\n",
       "     随访6流水号  HM_volume.6  随访7流水号  HM_volume.7  随访8流水号  HM_volume.8  \n",
       "0       NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "1       NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "2       NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "3       NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "4       NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "..      ...          ...     ...          ...     ...          ...  \n",
       "155     NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "156     NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "157     NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "158     NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "159     NaN          NaN     NaN          NaN     NaN          NaN  \n",
       "\n",
       "[160 rows x 18 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71e572f6-5905-42ee-8ef3-f4f452f5373e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df.to_excel('1a数据_已替换时间戳_已矫正.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfef420-d2b1-4973-a867-4b176b334668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值: 72.0475\n",
      "最大值: 72.8884\n",
      "最小值: 48.9889\n",
      "最大值: 49.6399\n",
      "最小值: 63.0587\n",
      "最大值: 126.5183\n",
      "最小值: 28.7249\n",
      "最大值: 43.2154\n",
      "最小值: 12.8142\n",
      "最大值: 31.1798\n",
      "最小值: 141.6898\n",
      "最大值: 210.1421\n",
      "最小值: 25.1009\n",
      "最大值: 30.6711\n",
      "最小值: 26.1919\n",
      "最大值: 45.0621\n",
      "最小值: 41.4982\n",
      "最大值: 57.3845\n",
      "最小值: 11.6497\n",
      "最大值: 34.5445\n",
      "最小值: 4.4614\n",
      "最大值: 5.2428\n",
      "最小值: 63.1578\n",
      "最大值: 64.2348\n",
      "最小值: 13.6857\n",
      "最大值: 14.0256\n",
      "最小值: 29.7303\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "#线性\n",
    "def liner_func(x,a,b,c,d):\n",
    "    return a*x+b\n",
    "\n",
    "#二次\n",
    "def erchi_func(x,a,b,c,d):\n",
    "    return a*x**2+b*x+c\n",
    "\n",
    "#三次\n",
    "def sanchi_func(x,a,b,c,d):\n",
    "    return a*x**3+b*x**2+c*x+d\n",
    "\n",
    "# 三角函数\n",
    "def trig_func(x,a,b,c,d):\n",
    "    return a*np.sin(x)+b*np.cos(x)+c\n",
    "# 指数曲线\n",
    "def target_func(x, a, b, c, d):\n",
    "    return a * np.exp(-x / b) + c\n",
    "# 对数函数\n",
    "def hyp_func(x, a,b,c,d):\n",
    "    return a*np.log(x)+b\n",
    "\n",
    "def __sst(y_no_fitting):\n",
    "    \"\"\"\n",
    "    计算SST(total sum of squares) 总平方和\n",
    "    :param y_no_predicted: List[int] or array[int] 待拟合的y\n",
    "    :return: 总平方和SST\n",
    "    \"\"\"\n",
    "    y_mean = sum(y_no_fitting) / len(y_no_fitting)\n",
    "    s_list =[(y - y_mean)**2 for y in y_no_fitting]\n",
    "    sst = sum(s_list)\n",
    "    return sst\n",
    "\n",
    "\n",
    "def __ssr(y_fitting, y_no_fitting):\n",
    "    \"\"\"\n",
    "    计算SSR(regression sum of squares) 回归平方和\n",
    "    :param y_fitting: List[int] or array[int]  拟合好的y值\n",
    "    :param y_no_fitting: List[int] or array[int] 待拟合y值\n",
    "    :return: 回归平方和SSR\n",
    "    \"\"\"\n",
    "    y_mean = sum(y_no_fitting) / len(y_no_fitting)\n",
    "    s_list =[(y - y_mean)**2 for y in y_fitting]\n",
    "    ssr = sum(s_list)\n",
    "    return ssr\n",
    "\n",
    "\n",
    "def __sse(y_fitting, y_no_fitting):\n",
    "    \"\"\"\n",
    "    计算SSE(error sum of squares) 残差平方和\n",
    "    :param y_fitting: List[int] or array[int] 拟合好的y值\n",
    "    :param y_no_fitting: List[int] or array[int] 待拟合y值\n",
    "    :return: 残差平方和SSE\n",
    "    \"\"\"\n",
    "    s_list = [(y_fitting[i] - y_no_fitting[i])**2 for i in range(len(y_fitting))]\n",
    "    sse = sum(s_list)\n",
    "    return sse\n",
    "\n",
    "\n",
    "def goodness_of_fit(y_fitting, y_no_fitting):\n",
    "    \"\"\"\n",
    "    计算拟合优度R^2\n",
    "    :param y_fitting: List[int] or array[int] 拟合好的y值\n",
    "    :param y_no_fitting: List[int] or array[int] 待拟合y值\n",
    "    :return: 拟合优度R^2\n",
    "    \"\"\"\n",
    "    SSR = __ssr(y_fitting, y_no_fitting)\n",
    "    SST = __sst(y_no_fitting)\n",
    "    rr = SSR /SST\n",
    "    return rr\n",
    "def selected_func(you,model,model_select):\n",
    "    maxyou=max(you)\n",
    "    for s in range(len(you)):\n",
    "        if you[s]==maxyou:\n",
    "            return model[s],model_select[s]\n",
    "        \n",
    "#========================粒子群=======================================\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def particle_swarm_optimization(mm, objective_func, num_particles, max_iterations,parm):\n",
    "    # 初始化参数\n",
    "    dimensions = 1\n",
    "    inertia = 0.5  # 惯性权重\n",
    "    cognitive_weight = 1.0  # 学习因子\n",
    "    social_weight = 1.0  # 学习因子\n",
    "    min_bound = 0  # 变量的最小边界\n",
    "    max_bound = 2  # 变量的最大边界\n",
    "\n",
    "    # 初始化粒子的位置和速度\n",
    "    particles = np.random.uniform(min_bound, max_bound, (num_particles, dimensions))\n",
    "    velocities = np.zeros((num_particles, dimensions))\n",
    "    if mm==1:\n",
    "        # 初始化粒子的局部最佳位置和全局最佳位置\n",
    "        personal_best_positions = particles.copy()\n",
    "        global_best_position = particles[np.argmin(objective_func(particles,parm[0],parm[1],parm[2],parm[3]))]\n",
    "\n",
    "        # 迭代更新粒子的速度和位置\n",
    "        for _ in range(max_iterations):\n",
    "            for i in range(num_particles):\n",
    "                # 更新粒子的速度\n",
    "                velocities[i] = (inertia * velocities[i] +\n",
    "                                cognitive_weight * np.random.rand() * (personal_best_positions[i] - particles[i]) +\n",
    "                                social_weight * np.random.rand() * (global_best_position - particles[i]))\n",
    "\n",
    "                # 限制速度范围\n",
    "                velocities[i] = np.clip(velocities[i], min_bound, max_bound)\n",
    "\n",
    "                # 更新粒子的位置\n",
    "                particles[i] += velocities[i]\n",
    "\n",
    "                # 限制位置范围\n",
    "                particles[i] = np.clip(particles[i], min_bound, max_bound)\n",
    "\n",
    "                # 更新局部最佳位置和全局最佳位置\n",
    "                if objective_func(particles[i],parm[0],parm[1],parm[2],parm[3]) < objective_func(personal_best_positions[i],parm[0],parm[1],parm[2],parm[3]):\n",
    "                    personal_best_positions[i] = particles[i]\n",
    "\n",
    "                if objective_func(particles[i],parm[0],parm[1],parm[2],parm[3]) < objective_func(global_best_position,parm[0],parm[1],parm[2],parm[3]):\n",
    "                    global_best_position = particles[i]\n",
    "        return global_best_position, objective_func(global_best_position,parm[0],parm[1],parm[2],parm[3])\n",
    "    if mm==-1:\n",
    "        # 初始化粒子的局部最佳位置和全局最佳位置\n",
    "        personal_best_positions = particles.copy()\n",
    "        global_best_position = particles[np.argmin(-objective_func(particles,parm[0],parm[1],parm[2],parm[3]))]\n",
    "\n",
    "        # 迭代更新粒子的速度和位置\n",
    "        for _ in range(max_iterations):\n",
    "            for i in range(num_particles):\n",
    "                # 更新粒子的速度\n",
    "                velocities[i] = (inertia * velocities[i] +\n",
    "                                cognitive_weight * np.random.rand() * (personal_best_positions[i] - particles[i]) +\n",
    "                                social_weight * np.random.rand() * (global_best_position - particles[i]))\n",
    "\n",
    "                # 限制速度范围\n",
    "                velocities[i] = np.clip(velocities[i], min_bound, max_bound)\n",
    "\n",
    "                # 更新粒子的位置\n",
    "                particles[i] += velocities[i]\n",
    "\n",
    "                # 限制位置范围\n",
    "                particles[i] = np.clip(particles[i], min_bound, max_bound)\n",
    "\n",
    "                # 更新局部最佳位置和全局最佳位置\n",
    "                if -objective_func(particles[i],parm[0],parm[1],parm[2],parm[3]) < -objective_func(personal_best_positions[i],parm[0],parm[1],parm[2],parm[3]):\n",
    "                    personal_best_positions[i] = particles[i]\n",
    "\n",
    "                if -objective_func(particles[i],parm[0],parm[1],parm[2],parm[3]) < -objective_func(global_best_position,parm[0],parm[1],parm[2],parm[3]):\n",
    "                    global_best_position = particles[i]\n",
    "    # 输出结果\n",
    "        return global_best_position, -objective_func(global_best_position,parm[0],parm[1],parm[2],parm[3])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "Set={}\n",
    "youSet={}\n",
    "for index, row in selected_df.iterrows():\n",
    "    if index >= 100:\n",
    "        break\n",
    "    # 去除NaN值\n",
    "    data = row.values[~np.isnan(row.values)]\n",
    "    # 将数据分成x和y坐标对\n",
    "    x = data[::2] / (3600 * 24)\n",
    "    y = data[1::2]/1000\n",
    "    \n",
    "    you=[]\n",
    "    model=[]\n",
    "    model_select=[]\n",
    "    you_index={}\n",
    "    try:\n",
    "        a1 = np.polyfit(x, y, 1)#线性\n",
    "        you1 = goodness_of_fit([liner_func(x[p],a1[0],a1[1]) for p in range(len(x))],y)\n",
    "        you.append(you1)\n",
    "        model.append({'回归类型':'线性回归','回归系数':a1})\n",
    "        you_index['线性回归']=you1\n",
    "        model_select.append((liner_func,a1+[0,0]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        a2 = np.polyfit(x, y, 2)#二次\n",
    "        you2 = goodness_of_fit([erchi_func(x[p],a2[0],a2[1],a2[2]) for p in range(len(x))],y)\n",
    "        you.append(you2)\n",
    "        model.append({'回归类型':'二次函数回归','回归系数':a2})\n",
    "        you_index['二次函数回归']=you2\n",
    "        model_select.append((erchi_func,a2+[0]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        a3 = np.polyfit(x, y, 3)#三次\n",
    "        you3 = goodness_of_fit([sanchi_func(x[p],a3[0],a3[1],a3[2],a3[3]) for p in range(len(x))],y)\n",
    "        you.append(you3)\n",
    "        model.append({'回归类型':'三次函数回归','回归系数':a3})\n",
    "        you_index['三次函数回归']=you3\n",
    "        model_select.append((sanchi_func,a3))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #拟合三角函数模型\n",
    "    try:\n",
    "        a4,_=optimize.curve_fit(trig_func,x,y)\n",
    "        you4 = goodness_of_fit([trig_func(x[p],a4[0],a4[1],a4[2]) for p in range(len(x))],y)\n",
    "        you.append(you4)\n",
    "        model.append({'回归类型':'三角函数回归','回归系数':a4})\n",
    "        you_index['三角函数回归']=you4\n",
    "        model_select.append((trig_func,a4+[0]))\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #拟合指数函数模型\n",
    "    try:\n",
    "        a5,_=optimize.curve_fit(target_func,x,y)\n",
    "        you5 = goodness_of_fit([target_func(x[p], a5[0], a5[1], a5[2]) for p in range(len(x))],y)\n",
    "        you.append(you5)\n",
    "        model.append({'回归类型':'指数函数回归','回归系数':a5})\n",
    "        you_index['指数函数回归']=you5\n",
    "        model_select.append((target_func,a5+[0]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #拟合对数函数模型\n",
    "    try:\n",
    "        a6,_=optimize.curve_fit(hyp_func,x,y)\n",
    "        you6 = goodness_of_fit([hyp_func(x[p], a6[0],a6[1]) for p in range(len(x))],y)\n",
    "        you.append(you6)\n",
    "        model.append({'回归类型':'对数函数回归','回归系数':a6})\n",
    "        you_index['对数函数回归']=you6\n",
    "        model_select.append((hyp_func,a6+[0,0]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # model=[f'线性回归，系数为{a1}',f'二次函数回归，系数为{a2}',f'三次函数回归，系数为{a3}',f'三角函数回归，系数为{a4}',f'指数函数回归，系数为{a5}',f'对数函数回归，系数为{a6}']\n",
    "    res,model_=selected_func(you,model,model_select)\n",
    "    \n",
    "    Set[index]=res\n",
    "    youSet[index]=you_index\n",
    "    best_position, best_value = particle_swarm_optimization(1,model_[0], 50, 100,model_[1])\n",
    "    best_value=round(float(best_value),4)\n",
    "    print(\"最小值:\",best_value)\n",
    "    best_position, best_value = particle_swarm_optimization(-1,model_[0], 50, 100,model_[1])\n",
    "    best_value=round(float(-best_value),4)\n",
    "    print(\"最大值:\", best_value)\n",
    "    \n",
    "dicts1 = [{key: value for key, value in Set[row].items()} for row in Set]\n",
    "df1 = pd.DataFrame(dicts1)\n",
    "df1.to_excel('血肿1a_100人拟合函数选择结果.xlsx')\n",
    "dicts2 = [{key: value for key, value in youSet[row].items()} for row in youSet]\n",
    "df2 = pd.DataFrame(dicts2)\n",
    "df2.to_excel('血肿1a_100人拟合优度.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e8992-9f94-49eb-bac1-f6edf4ddcfde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c11b2-27b8-41ea-b30a-aeb553bb33e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388f006-96a2-454b-9506-3ac2f0d40919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d61b0-48ab-4d94-8579-98d682f26fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
