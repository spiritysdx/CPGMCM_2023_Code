{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e48b49f-4ce9-45e7-a506-8638371e6530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'init': 'k-means++', 'max_iter': 5, 'n_clusters': 5, 'random_state': 2}\n",
      "Clustering Algorithm: K-Means (Tuned), Clustering Labels: [1 4 1 4 4 3 0 2 4 2 3 4 2 4 0 1 2 4 4 4 1 0 2 2 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 3 1 1 3 1 0 3 3 3 1 1\n",
      " 3 1 1 2 2 1 0 1 1 1 1 3 1 2 3 1 0 3 2 1 1 3 1 1 1 1 1 4 0 4 0 0 0 2 1 4 4\n",
      " 0 4 0 2 2 4 4 4 3 2 3 0 2 4 4 0 1 1 1], Silhouette coefficient: 0.5951914211495353, Calinski-Harabasz index: 50.374236800495346\n",
      "Best Parameters: {'init': 'k-means++', 'max_iter': 5, 'n_clusters': 5, 'random_state': 2}\n",
      "Best Parameters: {'init': 'k-means++', 'max_iter': 1, 'n_clusters': 5, 'random_state': None}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mKMeans(), param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 执行网格搜索\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(data)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 输出最佳参数\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:727\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1530\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m kmeans_single(\n\u001b[1;32m   1531\u001b[0m     X,\n\u001b[1;32m   1532\u001b[0m     sample_weight,\n\u001b[1;32m   1533\u001b[0m     centers_init,\n\u001b[1;32m   1534\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1535\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1536\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol,\n\u001b[1;32m   1537\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_threads,\n\u001b[1;32m   1538\u001b[0m )\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1546\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1548\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:728\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[1;32m    724\u001b[0m         labels_old[:] \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict_convergence:\n\u001b[1;32m    727\u001b[0m         \u001b[38;5;66;03m# rerun E-step so that predicted labels match cluster centers\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m         lloyd_iter(\n\u001b[1;32m    729\u001b[0m             X,\n\u001b[1;32m    730\u001b[0m             sample_weight,\n\u001b[1;32m    731\u001b[0m             centers,\n\u001b[1;32m    732\u001b[0m             centers,\n\u001b[1;32m    733\u001b[0m             weight_in_clusters,\n\u001b[1;32m    734\u001b[0m             labels,\n\u001b[1;32m    735\u001b[0m             center_shift,\n\u001b[1;32m    736\u001b[0m             n_threads,\n\u001b[1;32m    737\u001b[0m             update_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    738\u001b[0m         )\n\u001b[1;32m    740\u001b[0m inertia \u001b[38;5;241m=\u001b[39m _inertia(X, sample_weight, centers, labels, n_threads)\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia, centers, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32msklearn/cluster/_k_means_lloyd.pyx:99\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/sklearn/utils/extmath.py:78\u001b[0m, in \u001b[0;36mrow_norms\u001b[0;34m(X, squared)\u001b[0m\n\u001b[1;32m     76\u001b[0m     norms \u001b[38;5;241m=\u001b[39m csr_row_norms(X)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mij,ij->i\u001b[39m\u001b[38;5;124m\"\u001b[39m, X, X)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m     81\u001b[0m     np\u001b[38;5;241m.\u001b[39msqrt(norms, norms)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter-env/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1371\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[1;32m   1370\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_einsum(\u001b[38;5;241m*\u001b[39moperands, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import warnings\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from sympy import symbols, Eq, solve\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "best_labels_best = []\n",
    "silhouette_best = 0\n",
    "ch_index_best = 0\n",
    "for i in range(0, 100):\n",
    "    # 示例数据\n",
    "    data7 = pd.read_excel('2b数据处理结果.xlsx')\n",
    "    data_p1 = data7[list(data7.columns)[13:]][:101]\n",
    "    data_p2 = data7[list(data7.columns)[13:]][131:]\n",
    "    data = pd.concat([data_p1, data_p2], axis=0, ignore_index=True)\n",
    "\n",
    "    # 定义所需的聚类算法和参数\n",
    "    clustering_algorithms = [\n",
    "        (\"K-Means\", KMeans())  # 不需要指定初始参数\n",
    "    ]\n",
    "\n",
    "    # 定义KMeans的超参数搜索范围\n",
    "    param_grid = {\n",
    "        'n_clusters': [None, 3, 4, 5],  # 尝试不同的聚类数量\n",
    "        'init': [None, 'k-means++', 'random'],  # 不同的初始化方法\n",
    "        'max_iter': [None, 1,5,10,25,50,100],  # 不同的最大迭代次数\n",
    "        'random_state': [None, 0,1,2], \n",
    "    }\n",
    "\n",
    "    # 创建GridSearchCV对象\n",
    "    grid_search = GridSearchCV(estimator=KMeans(), param_grid=param_grid, cv=5)\n",
    "\n",
    "    # 执行网格搜索\n",
    "    grid_search.fit(data)\n",
    "\n",
    "    # 输出最佳参数\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "    # 获取最佳参数的KMeans模型\n",
    "    best_kmeans_model = grid_search.best_estimator_\n",
    "\n",
    "    # 使用最佳模型进行聚类\n",
    "    best_kmeans_model.fit(data)\n",
    "    best_labels = best_kmeans_model.labels_\n",
    "\n",
    "    # 计算评估指标\n",
    "    silhouette = silhouette_score(data, best_labels)\n",
    "    ch_index = calinski_harabasz_score(data, best_labels)\n",
    "\n",
    "    # print(\"Clustering Algorithm: K-Means (Tuned)\")\n",
    "    # print(\"Clustering Labels:\", best_labels)\n",
    "    # print(\"Silhouette coefficient:\", silhouette)\n",
    "    # print(\"Calinski-Harabasz index:\", ch_index)\n",
    "    if silhouette > silhouette_best:\n",
    "        silhouette_best = silhouette.copy()\n",
    "        best_labels_best = best_labels.copy()\n",
    "        ch_index_best = ch_index.copy()\n",
    "        print(f\"Clustering Algorithm: K-Means (Tuned), Clustering Labels: {best_labels}, Silhouette coefficient: {silhouette}, Calinski-Harabasz index: {ch_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f81d3-9e2e-49c5-83b5-a350a119d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "# 比例变量变数值变量，归一化的是数值变量\n",
    "# 假设data5是你的数据框\n",
    "hm_columns = data5.filter(like='HM_').columns.tolist()\n",
    "ed_columns = data5.filter(like='ED_').columns.tolist()\n",
    "hm_columns.pop(0)\n",
    "ed_columns.pop(0)\n",
    "# print(ed_columns)\n",
    "\n",
    "# 获取'HM_volume'和'ED_volume.0'列的值\n",
    "hm_volume = data5['HM_volume']\n",
    "ed_volume = data5['ED_volume']\n",
    "\n",
    "# 将以'HM_'开头的列与'HM_volume'相乘\n",
    "data5[hm_columns] = data5[hm_columns].mul(hm_volume, axis=0)\n",
    "\n",
    "# 将以'ED_'开头的列与'ED_volume.0'相乘\n",
    "data5[ed_columns] = data5[ed_columns].mul(ed_volume, axis=0)\n",
    "# 创建 MinMaxScaler 对象\n",
    "scaler = MinMaxScaler()\n",
    "# 选择要归一化的列（除了 '年龄' 列之外的所有列）\n",
    "columns_to_normalize = [col for col in data5.columns if col != '性别']\n",
    "# 使用 MinMaxScaler 对所选列进行归一化\n",
    "data5[columns_to_normalize] = scaler.fit_transform(data5[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aee26f-9fce-46dc-90bb-46c1cc50fbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Clustering Algorithm: K-Means (Tuned), Clustering Labels: {best_labels_best}, Silhouette coefficient: {silhouette_best}, Calinski-Harabasz index: {ch_index_best}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e45be2-cb7b-4cfb-b5a9-1421ebbbd4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# json.load()\n",
    "# 0.694\n",
    "# 创建一个包含数组的字典\n",
    "data = {\"best_labels_130\": best_labels_best.tolist()}\n",
    "\n",
    "# 保存为JSON文件\n",
    "with open(\"best_labels_130.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)\n",
    "\n",
    "# 要在其他Python脚本中读取这个JSON文件，你可以使用json.load()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f73f4-8f7f-474c-b90f-8157d5161e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a313b04-78ad-41b3-a169-bebde2bad1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963f837-7db2-4ad7-880f-8c36a4eca20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bce40b-b0af-4eaf-bdef-07b09bcd73e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
