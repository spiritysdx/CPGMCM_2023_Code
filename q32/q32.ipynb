{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d0fd9-66e9-4c45-8bdd-5a9fdc2f146e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import warnings\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from sympy import symbols, Eq, solve\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a969533-a831-4a68-8b05-fd285b41b45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_excel('3b数据.xlsx').drop(['数据集划分'], axis=1)\n",
    "data1.rename(columns={'HM_volume': 'HM_volume.0', \n",
    "                      'HM_ACA_R_Ratio': 'HM_ACA_R_Ratio.0', \n",
    "                      'HM_MCA_R_Ratio': 'HM_MCA_R_Ratio.0', \n",
    "                      'HM_PCA_R_Ratio': 'HM_PCA_R_Ratio.0', \n",
    "                      'HM_Pons_Medulla_R_Ratio': 'HM_Pons_Medulla_R_Ratio.0', \n",
    "                      'HM_Cerebellum_R_Ratio': 'HM_Cerebellum_R_Ratio.0', \n",
    "                      'HM_ACA_L_Ratio':'HM_ACA_L_Ratio.0', \n",
    "                      'HM_MCA_L_Ratio':'HM_MCA_L_Ratio.0', \n",
    "                      'HM_PCA_L_Ratio':'HM_PCA_L_Ratio.0', \n",
    "                      'HM_Pons_Medulla_L_Ratio':'HM_Pons_Medulla_L_Ratio.0', \n",
    "                      'HM_Cerebellum_L_Ratio':'HM_Cerebellum_L_Ratio.0'\n",
    "                     }, inplace=True)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343af6ed-80ab-42cf-a704-4c75d945c89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list(data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be176008-69ba-47d3-9e9a-fae8dff5b4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 转换独热编码\n",
    "xueya_list = []\n",
    "for i in data1['血压']:\n",
    "    y1 = i.split('/')[0]\n",
    "    y2 = i.split('/')[1]\n",
    "    if int(y1) > 139 or int(y1) < 90:\n",
    "        status_i = 0\n",
    "    elif int(y2) > 89 or int(y2) < 60:\n",
    "        status_i = 0\n",
    "    else:\n",
    "        status_i = 1\n",
    "    xueya_list.append(status_i)\n",
    "data1['血压'] = np.array(xueya_list)\n",
    "data1['性别_男'] = data1['性别'].apply(lambda x: 1 if x == '男' else 0)\n",
    "data1['性别_女'] = data1['性别'].apply(lambda x: 1 if x == '女' else 0)\n",
    "data1 = data1.drop(columns=['性别'])\n",
    "x = data1['年龄'].values\n",
    "scaler = MinMaxScaler()\n",
    "x_normalized = scaler.fit_transform(x.reshape(-1, 1))\n",
    "binarizer = Binarizer(threshold=0.5)\n",
    "x_binarized = binarizer.fit_transform(x_normalized)\n",
    "data1['年龄'] = x_binarized\n",
    "data1 = data1.drop(['流水号'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586f18e-63b5-49cb-9c5e-3f0c8388dfb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "import re\n",
    "\n",
    "# 使用正则表达式来匹配列名中的末尾标识符（.1到.8）\n",
    "pattern = r'\\.\\d+$'\n",
    "\n",
    "hm_columns = data1.filter(like='HM_').columns.tolist()\n",
    "ed_columns = data1.filter(like='ED_').columns.tolist()\n",
    "\n",
    "# 获取匹配'.1'到'.8'的列名\n",
    "hm_match_columns = [col for col in hm_columns if re.search(pattern, col)]\n",
    "ed_match_columns = [col for col in ed_columns if re.search(pattern, col)]\n",
    "\n",
    "# 将匹配的列与相应的'volume'列相乘\n",
    "for col in hm_match_columns:\n",
    "    match_volume_col = f'HM_volume{re.search(pattern, col).group()}'\n",
    "    data1[col] = data1[col] * data1[match_volume_col]\n",
    "\n",
    "for col in ed_match_columns:\n",
    "    match_volume_col = f'ED_volume{re.search(pattern, col).group()}'\n",
    "    data1[col] = data1[col] * data1[match_volume_col]\n",
    "\n",
    "# 创建 MinMaxScaler 对象\n",
    "scaler = MinMaxScaler()\n",
    "# 选择要归一化的列（除了 '年龄' 列之外的所有列）\n",
    "columns_to_normalize = [col for col in data1.columns if col != '性别' and col != 'ID' and col != '90天mRS']\n",
    "# 使用 MinMaxScaler 对所选列进行归一化\n",
    "data1[columns_to_normalize] = scaler.fit_transform(data1[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a361d0-77b9-4cd9-ab97-94f7668c14ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生成总体积的列名\n",
    "numbers = list(range(9))\n",
    "combined_list = []\n",
    "combined_list += [f'HM_volume.{num}' for num in numbers] + [f'ED_volume.{num}' for num in numbers] \n",
    "combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f5906-479e-4a91-9657-dad1b64cffe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = data1.drop(['ID']+combined_list, axis = 1)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357cb6e-4c2d-45d1-aed5-a9c3fad8a439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2_p1 = data2[:100]\n",
    "data2_p2 = data2[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f0d65-3a86-448b-9d98-ad17f75e791f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2_p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cbbd0-4fef-4825-a3d5-2fef40b7df32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2_need_pca = data1.drop(['ID']+combined_list, axis = 1)\n",
    "data2_need_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2aebd-0d8d-4436-ae0b-19137865476c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data2_need_pca.to_csv('data2_need_pca.csv', index=False)\n",
    "# 计算每列的空值占比\n",
    "missing_percentage = (data2_need_pca.isnull().sum() / len(data2_need_pca)) * 100\n",
    "\n",
    "# 找到占比大于20%的列 - 除去第一列(因为是y轴 - 90天RMS)\n",
    "columns_to_drop = missing_percentage[missing_percentage > 20].index.tolist()\n",
    "\n",
    "print(columns_to_drop)\n",
    "\n",
    "# 创建一个新的DataFrame来存储被删除的列\n",
    "deleted_columns_df = data2_need_pca[columns_to_drop]\n",
    "\n",
    "# 从data2_need_pca中删除这些列\n",
    "data2_need_pca.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# 打印被删除的列\n",
    "print(\"被删除的列：\")\n",
    "print(list(deleted_columns_df.columns))\n",
    "\n",
    "# 现在data2_need_pca中只包含占比不大于20%的列\n",
    "# print(\"处理后的data2_need_pca：\")\n",
    "# print(data2_need_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aa734-93e9-4a03-ae49-c6ea6306a7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设data2_need_pca是你的DataFrame，其中第一列是y，其他列是x，包括缺失值\n",
    "y = data2_need_pca.iloc[:, 0]\n",
    "X = data2_need_pca.iloc[:, 1:]\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 使用迭代PCA的方式处理缺失值\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)  # 可以根据需要调整max_iter参数\n",
    "X_imputed = imputer.fit_transform(X_scaled)\n",
    "\n",
    "# 初始化PCA模型\n",
    "pca = PCA()\n",
    "\n",
    "# 拟合PCA模型\n",
    "pca.fit(X_imputed)\n",
    "\n",
    "# 累积解释方差比例\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "# 绘制累积解释方差比例的图形\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance vs. Number of Principal Components')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 寻找最接近0.9的累积解释方差的维度\n",
    "target_variance = 0.9\n",
    "optimal_dimension = next(i for i, var in enumerate(cumulative_explained_variance) if var >= target_variance) + 1  # 加1是因为索引从0开始\n",
    "\n",
    "# 根据最优维度重新进行PCA\n",
    "pca = PCA(n_components=optimal_dimension)\n",
    "X_pca = pca.fit_transform(X_imputed)\n",
    "\n",
    "# 创建一个新的DataFrame包含最优维度的主成分\n",
    "column_names = [f\"PC{i+1}\" for i in range(optimal_dimension)]\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=column_names)\n",
    "\n",
    "# 将y列添加回DataFrame\n",
    "df_pca['y'] = y\n",
    "\n",
    "# 打印最优维度\n",
    "print(f\"最优维度: {optimal_dimension}\")\n",
    "\n",
    "# 保存新的DataFrame到文件\n",
    "df_pca.to_csv('pca_result.csv', index=False)  # 保存到csv文件中，你可以修改文件名和路径\n",
    "\n",
    "# 打印新的DataFrame的前几行\n",
    "df_pca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e509b-db89-4a28-b8b4-ba308f0928a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fd8af-8a1a-43dc-98e7-f544cc03d11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675b517-a86b-4f42-9f81-b3929fac3328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ecc16-3b30-4470-b9ad-21f36f4d41d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
